# -*- coding: utf-8 -*-
"""udn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fUsaIfrG0EI9WlyMjzAHYWLN0PCADKUE
"""

from scrapy.spiders import CrawlSpider, Rule
from scrapy.linkextractors import LinkExtractor

class UdnSpider(CrawlSpider):
    name = 'udn'   # 定義spider 名稱
    custom_settings={
      'DOWNLOAD_DELAY':'3',  # 設定爬蟲時間延遲
      'FEED_EXPORT_ENCODING':'utf-8', # 設定文字編碼
    }
    allowed_domains = ['udn.com']  # 爬蟲執行網域

    start_urls = ['https://udn.com/search/word/2/%E8%94%A1%E8%8B%B1%E6%96%87']  #爬蟲起始網頁
    allow_list = ['https://udn\.com/news/story/\d+/\d+'] #需要分析之網址格式

    # 當網址的格式符合allow_list的格式時，使用parse_item函式解析網頁，
    # 把網頁內的所有超連結加入追蹤清單中
    rules = [Rule(LinkExtractor(allow=allow_list), callback='parse_item', follow=True)]

    def parse_item(self, response):
        # 取出網頁新聞標題
        title = response.css('h1.article-content__title::text').get()
        # 取出網頁新聞內容
        ps = response.css('section.article-content__editor p::text').getall()
        content = ''.join(ps)
        # 取出網址
        url = response.url
        yield {
          'title':title,
          'content':content,
          'url':url,
        }